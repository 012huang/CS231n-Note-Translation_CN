
[Source](https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit "Permalink to 贺完结！CS231n官方笔记授权翻译总集篇发布 - 知乎专栏")

# 贺完结！CS231n官方笔记授权翻译总集篇发布 - 知乎专栏

{"database":{"Post":{"21930884":{"title":"贺完结！CS231n官方笔记授权翻译总集篇发布","author":"du-ke","content":"

&gt; 哈哈哈！我们也是不谦虚，几个"业余水平"的网友，怎么就"零星"地把这件事给搞完了呢！**总之就是非常开心**，废话不多说，进入正题吧！

## CS231n简介

CS231n的全称是[CS231n: Convolutional Neural Networks for Visual Recognition__][1]，即**面向视觉识别的卷积神经网络**。该课程是[斯坦福大学计算机视觉实验室__][2]推出的课程。需要注意的是，目前大家说CS231n，大都指的是2016年冬季学期（一月到三月）的最新版本。

**课程描述**：请允许我们引用课程主页上的**官方描述**如下。

&gt; 计算机视觉在社会中已经逐渐普及，并广泛运用于搜索检索、图像理解、手机应用、地图导航、医疗制药、无人机和无人驾驶汽车等领域。而这些应用的核心技术就是图像分类、图像定位和图像探测等视觉识别任务。近期神经网络（也就是"深度学习"）方法上的进展极大地提升了这些代表当前发展水平的视觉识别系统的性能。
&gt; 
&gt; 本课程将深入讲解深度学习框架的细节问题，聚焦面向视觉识别任务（尤其是图像分类任务）的端到端学习模型。在10周的课程中，学生们将会学习如何实现、训练和调试他们自己的神经网络，并建立起对计算机视觉领域的前沿研究方向的细节理解。最终的作业将包括训练一个有几百万参数的卷积神经网络，并将其应用到最大的图像分类数据库（ImageNet）上。我们将会聚焦于教授如何确定图像识别问题，学习算法（比如反向传播算法），对网络的训练和精细调整（fine-tuning）中的工程实践技巧，指导学生动手完成课程作业和最终的课程项目。本课程的大部分背景知识和素材都来源于[ImageNet Challenge__][3]竞赛。

**课程内容**：官方课程安排及资源获取请点击[这里__][4]，课程视频请在Youtube上查看[Andrej Karpathy__][5]创建的[播放列表__][6]，也可私信我们获取云盘视频资源。通过查看官方课程表，我们可以看到：CS231n课程资源主要由**授课视频与PPT**，**授课知识详解笔记**和**课程作业**三部分组成。其中：

* **授课视频15课**。每节课时约1小时左右，每节课一份PPT。  
* **授课知识详解笔记共9份**。光看课程视频是不够的，深入理解课程笔记才能比较扎实地学习到知识。
* **课程作业3次**。其中每次作业中又包含多个小作业，完成作业能确保对于课程关键知识的深入理解和实现。
* **课程项目1个**。这个更多是面向斯坦福的学生，组队实现课程项目。
* **拓展阅读若干**。课程推荐的拓展阅读大多是领域内的经典著作节选或论文，推荐想要深入学习的同学阅读。

**课程评价**：我们觉得赞！很多人都觉得赞！当然也有人觉得不好。具体如何，大家搜搜CS231n在网络，在知乎上的评价不就好了嘛！**个人认为**：入门深度学习的**一门良心课**。**适合绝大多数**想要学习深度学习知识的人。

**课程不足**：课程后期从RCNN开始就没有课程笔记。

  

## 课程学习方法

三句话总结：

* **看授课视频形成概念，发现个人感兴趣方向。**
* **读课程笔记理解细节，夯实工程实现的基础。  
**
* **码课程作业实现算法，积累实验技巧与经验。**

引用一下学习金字塔的图，意思大家都懂的：

![][7]

## 我们的工作

* **完成了CS231n全部9篇课程知识详解笔记的翻译**：  

原文：[[python/numpy tutorial]__][8]。

翻译：[Python Numpy教程][9]。

&gt; 我们将使用Python编程语言来完成本课程的所有作业。Python是一门伟大的通用编程语言，在一些常用库（numpy, scipy, matplotlib）的帮助下，它又会变成一个强大的科学计算环境。我们期望你们中大多数人对于Python语言和Numpy库比较熟悉，而对于没有Python经验的同学，这篇教程可以帮助你们快速了解Python编程环境和如何使用Python作为科学计算工具。

原文：[[image classification notes]__][10]。

翻译：[图像分类笔记（上）][11][（下）][12]。

&gt; 该笔记是一篇介绍性教程，面向非计算机视觉领域的同学。教程将向同学们介绍图像分类问题和数据驱动方法，内容列表：  

&gt; 
&gt; * 图像分类、数据驱动方法和流程  

&gt; * Nearest Neighbor分类器
&gt;     * k-Nearest Neighbor _译者注：上篇翻译截止处_  

&gt; * 验证集、交叉验证集和超参数调参  

&gt; * Nearest Neighbor的优劣  

&gt; * 小结  

&gt; * 小结：应用kNN实践  

&gt; * 拓展阅读

原文：[[linear classification notes]__][13]。  

翻译：线性分类笔记[（上）][14][（中）][15][（下）][16]。

&gt; 我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是**评分函数（score function）**，它是原始图像数据到类别分值的映射。另一个是**损失函数（loss function）**，它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。内容列表：  

&gt; 
&gt; * 线性分类器简介
&gt; * 线性评分函数
&gt; * 阐明线性分类器 _译者注：上篇翻译截止处_
&gt; * 损失函数
&gt;     * 多类SVM
&gt;     * Softmax分类器
&gt;     * SVM和Softmax的比较
&gt; * 基于Web的可交互线性分类器原型
&gt; * 小结

原文：[[optimization notes]__][17]。  

翻译：最优化笔记[（上）][18][（下）][19]。

&gt; 该笔记介绍了图像分类任务的第三个关键部分：最优化。内容列表如下：  

&gt; 
&gt; * 简介  

&gt; * 损失函数可视化
&gt; * 最优化
&gt;     * 策略#1：随机搜索
&gt;     * 策略#2：随机局部搜索
&gt;     * 策略#3：跟随梯度 _译者注：上篇截止处_
&gt; * 梯度计算
&gt;     * 使用有限差值进行数值计算
&gt;     * 微分计算梯度
&gt; * 梯度下降
&gt; * 小结

原文：[[backprop notes]__][20]。

翻译：[反向传播笔记][21]。

&gt; 该笔记本将帮助读者**对反向传播形成直观而专业的理解**。反向传播是利用链式法则递归计算表达式的梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。内容里列表如下：  

&gt; 
&gt; * 简介
&gt; * 简单表达式和理解梯度
&gt; * 复合表达式，链式法则，反向传播
&gt; * 直观理解反向传播
&gt; * 模块：Sigmoid例子
&gt; * 反向传播实践：分段计算
&gt; * 回传流中的模式
&gt; * 用户向量化操作的梯度
&gt; * 小结

原文：[Neural Nets notes 1__][22]。

翻译：神经网络笔记1[（上）][23][（下）][24]。

&gt; 该笔记介绍了神经网络的建模与结构，内容列表如下：  

&gt; 
&gt; * 不用大脑做类比的快速简介
&gt; * 单个神经元建模
&gt;     * 生物动机和连接
&gt;     * 作为线性分类器的单个神经元
&gt;     * 常用的激活函数 
&gt; * 神经网络结构
&gt;     * 层组织
&gt;     * 前向传播计算例子
&gt;     * 表达能力
&gt;     * 设置层的数量和尺寸
&gt; * 小节
&gt; * 参考文献

原文：[Neural Nets notes 2__][25]。

翻译：[神经网络笔记2][26]。

&gt; 该笔记介绍了数据的预处理，正则化和损失函数，内容列表如下：  

&gt; 
&gt; * 设置数据和模型
&gt;     * 数据预处理
&gt;     * 权重初始化
&gt;     * 批量归一化（Batch Normalization）
&gt;     * 正则化（L2/L1/Maxnorm/Dropout）
&gt; * 损失函数
&gt; * 小结

原文：[Neural Nets notes 3__][27]。

翻译：神经网络笔记3[（上）][28][（下）][29]。

&gt; 该笔记讲解了神经网络的动态部分，即神经网络学习参数和搜索最优超参数的过程。内容列表如下：  

&gt; 
&gt; * 梯度检查
&gt; * 合理性（Sanity）检查
&gt; * 检查学习过程
&gt; 
&gt; * 损失函数
&gt; * 训练集与验证集准确率
&gt; * 权重：更新比例
&gt; * 每层的激活数据与梯度分布
&gt; * 可视化 _译者注：上篇翻译截止处_
&gt; * 参数更新
&gt; 
&gt; * 一阶（随机梯度下降）方法，动量方法，Nesterov动量方法
&gt; * 学习率退火
&gt; * 二阶方法
&gt; * 逐参数适应学习率方法（Adagrad，RMSProp）
&gt; * 超参数调优
&gt; * 评价
&gt; * 总结
&gt; * 拓展引用

原文：[ConvNet notes__][30]。

翻译：[卷积神经网络笔记][31]。

&gt; 内容列表：
&gt; 
&gt; * **结构概述**
&gt; * **用来构建卷积神经网络的各种层**  

&gt;     * 卷积层
&gt;     * 汇聚层
&gt;     * 归一化层
&gt;     * 全连接层
&gt;     * 将全连接层转化成卷积层
&gt; * **卷积神经网络的结构**
&gt;     * 层的排列规律
&gt;     * 层的尺寸设置规律
&gt;     * 案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）
&gt;     * 计算上的考量
&gt; * **拓展资源**

  

* **完成了3个课程作业页面的翻译**：  

原文：[[Assignment #1]__][32]。  

翻译：[CS231n课程作业#1简介][33]。

&gt; 作业内容：实现k-NN，SVM分类器，Softmax分类器和两层神经网络，实践一个简单的图像分类流程。

原文：[[Assignment #2]__][34]。  

翻译：[CS231n课程作业#2简介][35]。

&gt; 作业内容：练习编写反向传播代码，训练神经网络和卷积神经网络。

原文：[[Assignment #3]__][36]。  

翻译：[CS231n课程作业#3简介][37]。

&gt; 作业内容：实现循环网络，并将其应用于在微软的COCO数据库上进行图像标注。实现DeepDream等有趣应用。

  

* **帮助知友[@智靖远][38]发起了在Youtube上合力翻译课程字幕的倡议**：

原文：[知友智靖远关于CS231n课程字幕翻译的倡议][39]。当时，[@智靖远][38]已经贡献了他对第一课字幕的翻译，目前这个翻译项目仍在进行中，欢迎各位知友积极参与。具体操作方式在倡议原文中有，请大家点击查看。

有很多知友私信我们，询问为何不做字幕。现在统一答复：**请大家积极参加[@智靖远][38]的字幕翻译项目。**他先进行的字幕贡献与翻译，我们**不能夺人之美**。**后续，我们也会向该翻译项目进行贡献**。

## 翻译团队

CS231n课程笔记的翻译，始于[@杜客][40]在一次回答问题"[应该选择TensorFlow还是Theano？][41]"中的机缘巧合，在[取得了授权][42]后申请了知乎专栏[智能单元 - 知乎专栏][43]独自翻译。随着翻译的进行，更多的知友参与进来。他们是[@ShiqingFan][44]，@[猴子][45]，[@堃堃][46]和[@李艺颖][47]。

**大家因为认同这件事而聚集在一起**，牺牲了很多个人的时间来进行翻译，校对和润色。而翻译的质量，我们不愿意自我表扬，还是**请各位知友自行阅读评价**吧。现在笔记翻译告一段落，下面是**团队成员的简短感言**：

[@ShiqingFan][44] ：一个偶然的机会让自己加入到这个翻译小队伍里来。CS231n给予了我知识的源泉和思考的灵感，前期的翻译工作也督促自己快速了学习了这门课程。虽然科研方向是大数据与并行计算，不过因为同时对深度学习比较感兴趣，于是乎现在的工作与两者都紧密相连。Merci!  

@[猴子][45]：在CS231n翻译小组工作的两个多月的时间非常难忘。我向杜客申请加入翻译小组的时候，才刚接触这门课不久，翻译和校对的工作让我对这门课的内容有了更深刻的理解。作为一个机器学习的初学者，我非常荣幸能和翻译小组一起工作并做一点贡献。希望以后能继续和翻译小组一起工作和学习。

[@堃堃][46] ：感谢组内各位成员的辛勤付出，很幸运能够参与这份十分有意义的工作，希望自己的微小工作能够帮助到大家，谢谢！  

[@李艺颖][47] ：当你真正沉下心来要做一件事情的时候才是学习和提高最好的状态；当你有热情做事时，并不会觉得是在牺牲时间，因为那是有意义并能带给你成就感和充实感的；不需要太过刻意地在乎大牛的巨大光芒，你只需像傻瓜一样坚持下去就好了，也许回头一看，你已前进了很多。就像老杜说的，我们就是每一步慢慢走，怎么就"零星"地把这件事给搞完了呢？  

[@杜客][40] ：做了一点微小的工作，哈哈。  

## 未来工作

目前通过大家的反馈，之后会有新的创作方向，会更多与大家互动，敬请期待吧！

## 感谢

感谢**所有给我们的翻译提出过批评指正的知友**，每篇文章末尾处的译者反馈部分我们都列出了大家的具体指正与贡献；

感谢**所有给我们的翻译点赞的知友**，你们的赞是我们的精神粮食；

感谢**给文章赞赏小钱钱的知友**，谢谢老板们：）

## 最后

**恳请大家点赞和分享到其他社交网络上**，让更多**想要入门与系统学习深度学习**的小伙伴能够看到这篇总集。同时，也欢迎大家在来专栏分享你的知识，发现志同道合的朋友！

**这个世界需要更多的英雄！**

","updated":"2016-08-25T07:47:00.000Z","canComment":false,"commentPermission":"anyone","commentCount":138,"collapsedCount":0,"likeCount":886,"state":"published","isLiked":false,"slug":"21930884","lastestTipjarors":[{"isFollowed":false,"name":"羊习习","headline":"","avatarUrl":"https://pic1.zhimg.com/da8e974dc_s.jpg","isFollowing":false,"type":"people","slug":"yang-xi-xi-54","profileUrl":"https://www.zhihu.com/people/yang-xi-xi-54","bio":"","hash":"b939d002b865d0f76263d09d3fed5a9f","uid":31159887069184,"isOrg":false,"description":"","isOrgWhiteList":false,"avatar":{"id":"da8e974dc","template":"https://pic1.zhimg.com/{id}_{size}.jpg"}},{"isFollowed":false,"name":"周洋","headline":"","avatarUrl":"https://pic1.zhimg.com/v2-5831107ff698ab4f582ab9fa9baa82f4_s.jpg","isFollowing":false,"type":"people","slug":"yzhou89","profileUrl":"https://www.zhihu.com/people/yzhou89","bio":" 程序员","hash":"7a58ff8d89b229bb3e801b953cf12b21","uid":773439518899454000,"isOrg":false,"description":"","isOrgWhiteList":false,"avatar":{"id":"v2-5831107ff698ab4f582ab9fa9baa82f4","template":"https://pic1.zhimg.com/{id}_{size}.jpg"}},{"isFollowed":false,"name":"老姨","headline":"","avatarUrl":"https://pic3.zhimg.com/8e9b2f0ba_s.jpg","isFollowing":false,"type":"people","slug":"lao-yi-67","profileUrl":"https://www.zhihu.com/people/lao-yi-67","bio":"老姨","hash":"9a35a3e18ba3f15c1838cbfff72ddc66","uid":36017134370816,"isOrg":false,"description":"","isOrgWhiteList":false,"avatar":{"id":"8e9b2f0ba","template":"https://pic3.zhimg.com/{id}_{size}.jpg"}},{"isFollowed":false,"name":"姜峰","headline":"计算机视觉，机器学习，SLAM，SFM，增强现实等，我全都不会！","avatarUrl":"https://pic2.zhimg.com/93041a1f8edb1d5d58b0dd9d80d2abf5_s.png","isFollowing":false,"type":"people","slug":"jiang-feng-60-80","profileUrl":"https://www.zhihu.com/people/jiang-feng-60-80","bio":"一个不合格的程序员","hash":"99029e001dc007b2c78c5f4dd9160b7f","uid":42913379647488,"isOrg":false,"description":"计算机视觉，机器学习，SLAM，SFM，增强现实等，我全都不会！","isOrgWhiteList":false,"avatar":{"id":"93041a1f8edb1d5d58b0dd9d80d2abf5","template":"https://pic2.zhimg.com/{id}_{size}.png"}},{"isFollowed":false,"name":"zhangxiaoyang","headline":"zhangxiaoyang.me | 微信公众号、知乎专栏：Yang的后花园","avatarUrl":"https://pic4.zhimg.com/e245a7467_s.jpg","isFollowing":false,"type":"people","slug":"yang-zhang-65-23","profileUrl":"https://www.zhihu.com/people/yang-zhang-65-23","bio":"爱美工的程序员","hash":"5123a6579a19c7481a954207d52db2c9","uid":48610444050432,"isOrg":false,"description":"zhangxiaoyang.me | 微信公众号、知乎专栏：Yang的后花园","isOrgWhiteList":false,"avatar":{"id":"e245a7467","template":"https://pic4.zhimg.com/{id}_{size}.jpg"}},{"isFollowed":false,"name":"sophie","headline":"创造出有价值的事物，并因此赢得尊重，对你的人生有掌控感，感到和他人有关联---------这些才激起人的热衷","avatarUrl":"https://pic1.zhimg.com/8875fd664f449d91cb9dc93a4b0fb8d8_s.jpg","isFollowing":false,"type":"people","slug":"di-di-12-42","profileUrl":"https://www.zhihu.com/people/di-di-12-42","bio":"无人机/德语/阅读/旅行","hash":"45b6db606a5d4acfdeddb4ef8bde0973","uid":43760956211200,"isOrg":false,"description":"创造出有价值的事物，并因此赢得尊重，对你的人生有掌控感，感到和他人有关联---------这些才激起人的热衷","isOrgWhiteList":false,"avatar":{"id":"8875fd664f449d91cb9dc93a4b0fb8d8","template":"https://pic1.zhimg.com/{id}_{size}.jpg"}},{"isFollowed":false,"name":"名师出高徒","headline":"","avatarUrl":"https://pic4.zhimg.com/v2-9d6aec84e930cde3b544e7500600f73b_s.jpg","isFollowing":false,"type":"people","slug":"ming-shi-chu-gao-tu-14","profileUrl":"https://www.zhihu.com/people/ming-shi-chu-gao-tu-14","bio":"人工智能工程师","hash":"ef02037ad2d2046ae799878ad2241bfa","uid":812648361697087500,"isOrg":false,"description":"","isOrgWhiteList":false,"avatar":{"id":"v2-9d6aec84e930cde3b544e7500600f73b","template":"https://pic4.zhimg.com/{id}_{size}.jpg"}},{"isFollowed":false,"name":"shelson woo","headline":"","avatarUrl":"https://pic1.zhimg.com/f3baff89c_s.jpg","isFollowing":false,"type":"people","slug":"shelson-woo","profileUrl":"https://www.zhihu.com/people/shelson-woo","bio":null,"hash":"3ce335fca1e2b39fdf599aa5ce464aff","uid":34104250728448,"isOrg":false,"description":"","isOrgWhiteList":false,"avatar":{"id":"f3baff89c","template":"https://pic1.zhimg.com/{id}_{size}.jpg"}}],"isTitleImageFullScreen":false,"rating":"none","titleImage":"https://pic3.zhimg.com/0dee7274beed25bd4abbcd76cb7d9576_r.jpg","links":{"comments":"/api/posts/21930884/comments"},"reviewers":["li-yi-ying-73","kun-kun-97-81","sqfan","hmonkey"],"topics":[{"url":"https://www.zhihu.com/topic/19559450","id":"19559450","name":"机器学习"},{"url":"https://www.zhihu.com/topic/19630200","id":"19630200","name":"资源共享"},{"url":"https://www.zhihu.com/topic/19566266","id":"19566266","name":"学习方法"}],"titleImageSize":{"width":990,"height":300},"href":"/api/posts/21930884","excerptTitle":"","column":{"slug":"intelligentunit","name":"智能单元"},"tipjarState":"activated","tipjarTagLine":"谢谢老板们","sourceUrl":"","pageCommentsCount":138,"tipjarorCount":39,"snapshotUrl":"","publishedTime":"2016-08-25T15:47:00+08:00","url":"/p/21930884","lastestLikers":[{"profileUrl":"https://www.zhihu.com/people/ukeso","bio":"INTJ/土木研究生/计算机爱好者","hash":"ae657ca955df5833722d7d535cf9d8c4","uid":29720980750336,"isOrg":false,"description":"","isOrgWhiteList":false,"slug":"ukeso","avatar":{"id":"ca40ae02f","template":"https://pic4.zhimg.com/{id}_{size}.jpg"},"name":"Akelio"},{"profileUrl":"https://www.zhihu.com/people/shi-min-2","bio":"","hash":"0ac8a16d0520661305708e8a8df61f9b","uid":29454197850112,"isOrg":false,"description":"","isOrgWhiteList":false,"slug":"shi-min-2","avatar":{"id":"b7c4e5fd735b7385e489e6ae21fb0439","template":"https://pic2.zhimg.com/{id}_{size}.jpg"},"name":"张恪"},{"profileUrl":"https://www.zhihu.com/people/xiao-jiu-wo-23","bio":null,"hash":"d64d24b2aab02ced07af11903246a983","uid":608671675525632000,"isOrg":false,"description":"","isOrgWhiteList":false,"slug":"xiao-jiu-wo-23","avatar":{"id":"565460bcb8a4626ef6bb676f24b05bf5","template":"https://pic2.zhimg.com/{id}_{size}.jpg"},"name":"小酒窝"},{"profileUrl":"https://www.zhihu.com/people/zou-zhi-sheng-55","bio":"电信","hash":"b58811bbbc258efc11ff4c017694dcb7","uid":574960850151018500,"isOrg":false,"description":"听民谣的二缺","isOrgWhiteList":false,"slug":"zou-zhi-sheng-55","avatar":{"id":"14e0128f6f423119201187ecb4ea5802","template":"https://pic3.zhimg.com/{id}_{size}.jpg"},"name":"舜十三"},{"profileUrl":"https://www.zhihu.com/people/zhao-kuang-yin-0","bio":"机器学习推荐算法","hash":"bf6a107d91946629480ff050e4dab41c","uid":612200273305800700,"isOrg":false,"description":"有情有义的做喜欢而有意义的事情","isOrgWhiteList":false,"slug":"zhao-kuang-yin-0","avatar":{"id":"v2-ae2da27a965c849fc5f9033c1de22333","template":"https://pic4.zhimg.com/{id}_{size}.jpg"},"name":"赵印"}],"summary":"![][48]哈哈哈！我们也是不谦虚，几个"业余水平"的网友，怎么就"零星"地把这件事给搞完了呢！**总之就是非常开心**，废话不多说，进入正题吧！CS231n简介CS231n的全称是[CS231n: Convolutional Neural Networks for Visual Recognition][49]，即**面向视觉识别的卷积神经网络**…","reviewingCommentsCount":0,"meta":{"previous":{"isTitleImageFullScreen":false,"rating":"none","titleImage":"https://pic3.zhimg.com/5b83bc8331994f47fedb1459d1424872_r.png","links":{"comments":"/api/posts/22038289/comments"},"topics":[{"url":"https://www.zhihu.com/topic/19551275","id":"19551275","name":"人工智能"},{"url":"https://www.zhihu.com/topic/19559450","id":"19559450","name":"机器学习"},{"url":"https://www.zhihu.com/topic/20043586","id":"20043586","name":"卷积神经网络（CNN）"}],"href":"/api/posts/22038289","excerptTitle":"","author":{"profileUrl":"https://www.zhihu.com/people/hmonkey","bio":"学生","hash":"77a6055b8d73148aee3464cf7a3b8d09","uid":557306122193793000,"isOrg":false,"description":"机器学习\深度学习方向初学者","isOrgWhiteList":false,"slug":"hmonkey","avatar":{"id":"f0c45ebc982d64ea0c4822517e7285ac","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"name":"猴子"},"content":"

**译者注**：本文翻译自斯坦福CS231n课程笔记[ConvNet notes__][30]，由课程教师[Andrej Karpathy__][50]授权进行翻译。本篇教程由[杜客][51]和[猴子][45]翻译完成，[堃堃][52]和[李艺颖][53]进行校对修改。

## 原文如下

内容列表：

* **结构概述**
* **用来构建卷积神经网络的各种层**  

    * 卷积层
    * 汇聚层
    * 归一化层
    * 全连接层
    * 将全连接层转化成卷积层
* **卷积神经网络的结构**
    * 层的排列规律
    * 层的尺寸设置规律
    * 案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）
    * 计算上的考量
* **拓展资源**

## **卷积神经网络（CNNs / ConvNets）**

卷积神经网络和上一章讲的常规神经网络非常相似：它们都是由神经元组成，神经元中有具有学习能力的权重和偏差。每个神经元都得到一些输入数据，进行内积运算后再进行激活函数运算。整个网络依旧是一个可导的评分函数：该函数的输入是原始的图像像素，输出是不同类别的评分。在最后一层（往往是全连接层），网络依旧有一个损失函数（比如SVM或Softmax），并且在神经网络中我们实现的各种技巧和要点依旧适用于卷积神经网络。

那么有哪些地方变化了呢？卷积神经网络的结构基于一个假设，即输入数据是图像，基于该假设，我们就向结构中添加了一些特有的性质。这些特有属性使得前向传播函数实现起来更高效，并且大幅度降低了网络中参数的数量。

## **结构概述**

_回顾：常规神经网络_。在上一章中，神经网络的输入是一个向量，然后在一系列的_隐层_中对它做变换。每个隐层都是由若干的神经元组成，每个神经元都与前一层中的所有神经元连接。但是在一个隐层中，神经元相互独立不进行任何连接。最后的全连接层被称为"输出层"，在分类问题中，它输出的值被看做是不同类别的评分值。

_常规神经网络对于大尺寸图像效果不尽人意_。在CIFAR-10中，图像的尺寸是32x32x3（宽高均为32像素，3个颜色通道），因此，对应的的常规神经网络的第一个隐层中，每一个单独的全连接神经元就有32x32x3=3072个权重。这个数量看起来还可以接受，但是很显然这个全连接的结构不适用于更大尺寸的图像。举例说来，一个尺寸为200x200x3的图像，会让神经元包含200x200x3=120,000个权重值。而网络中肯定不止一个神经元，那么参数的量就会快速增加！显而易见，这种全连接方式效率低下，大量的参数也很快会导致网络过拟合。

_神经元的三维排列_。卷积神经网络针对输入全部是图像的情况，将结构调整得更加合理，获得了不小的优势。与常规神经网络不同，卷积神经网络的各层中的神经元是3维排列的：**宽度**、**高度**和**深度**（这里的**深度**指的是激活数据体的第三个维度，而不是整个网络的深度，整个网络的深度指的是网络的层数）。举个例子，CIFAR-10中的图像是作为卷积神经网络的输入，该数据体的维度是32x32x3（宽度，高度和深度）。我们将看到，层中的神经元将只与前一层中的一小块区域连接，而不是采取全连接方式。对于用来分类CIFAR-10中的图像的卷积网络，其最后的输出层的维度是1x1x10，因为在卷积神经网络结构的最后部分将会把全尺寸的图像压缩为包含分类评分的一个向量，向量是在深度方向排列的。下面是例子：

![][54]![][55]左边是一个3层的神经网络。右边是一个卷积神经网络，图例中网络将它的神经元都排列成3个维度（宽、高和深度）。卷积神经网络的每一层都将3D的输入数据变化为神经元3D的激活数据并输出。在这个例子中，红色的输入层装的是图像，所以它的宽度和高度就是图像的宽度和高度，它的深度是3（代表了红、绿、蓝3种颜色通道）。![][54]

&gt; 卷积神经网络是由层组成的。每一层都有一个简单的API：用一些含或者不含参数的可导的函数，将输入的3D数据变换为3D的输出数据。

  

### **用来构建卷积网络的各种层**

一个简单的卷积神经网络是由各种层按照顺序排列组成，网络中的每个层使用一个可以微分的函数将激活数据从一个层传递到另一个层。卷积神经网络主要由三种类型的层构成：**卷积层**，**汇聚（Pooling）层**和**全连接层**（全连接层和常规神经网络中的一样）。通过将这些层叠加起来，就可以构建一个完整的卷积神经网络。

_网络结构例子：_这仅仅是个概述，下面会更详解的介绍细节。一个用于CIFAR-10图像数据分类的卷积神经网络的结构可以是[输入层-卷积层-ReLU层-汇聚层-全连接层]。细节如下：

* 输入[32x32x3]存有图像的原始像素值，本例中图像宽高均为32，有3个颜色通道。  
* 卷积层中，神经元与输入层中的一个局部区域相连，每个神经元都计算自己与输入层相连的小区域与自己权重的内积。卷积层会计算所有神经元的输出。如果我们使用12个滤波器（也叫作核），得到的输出数据体的维度就是[32x32x12]。  
* ReLU层将会逐个元素地进行激活函数操作，比如使用以0为阈值的!["max\(0,x\)"][56]作为激活函数。该层对数据尺寸没有改变，还是[32x32x12]。  
* 汇聚层在在空间维度（宽度和高度）上进行降采样（downsampling）操作，数据尺寸变为[16x16x12]。  
* 全连接层将会计算分类评分，数据尺寸变为[1x1x10]，其中10个数字对应的就是CIFAR-10中10个类别的分类评分值。正如其名，全连接层与常规神经网络一样，其中每个神经元都与前一层中所有神经元相连接。

由此看来，卷积神经网络一层一层地将图像从原始像素值变换成最终的分类评分值。其中有的层含有参数，有的没有。具体说来，卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数（神经元的突触权值和偏差）。而ReLU层和汇聚层则是进行一个固定不变的函数操作。卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了。

**小结**：

* 简单案例中卷积神经网络的结构，就是一系列的层将输入数据变换为输出数据（比如分类评分）。  
* 卷积神经网络结构中有几种不同类型的层（目前最流行的有卷积层、全连接层、ReLU层和汇聚层）。  
* 每个层的输入是3D数据，然后使用一个可导的函数将其变换为3D的输出数据。  
* 有的层有参数，有的没有（卷积层和全连接层有，ReLU层和汇聚层没有）。
* 有的层有额外的超参数，有的没有（卷积层、全连接层和汇聚层有，ReLU层没有）。
![][54]![][57]一个卷积神经网络的激活输出例子。左边的输入层存有原始图像像素，右边的输出层存有类别分类评分。在处理流程中的每个激活数据体是铺成一列来展示的。因为对3D数据作图比较困难，我们就把每个数据体切成层，然后铺成一列显示。最后一层装的是针对不同类别的分类得分，这里只显示了得分最高的5个评分值和对应的类别。完整的[网页演示__][58]在我们的课程主页。本例中的结构是一个小的VGG网络，VGG网络后面会有讨论。![][54]

现在讲解不同的层，层的超参数和连接情况的细节。

  

#### 卷积层

卷积层是构建卷积神经网络的核心层，它产生了网络中大部分的计算量。

**概述和直观介绍**：首先讨论的是，在没有大脑和生物意义上的神经元之类的比喻下，卷积层到底在计算什么。卷积层的参数是有一些可学习的滤波器集合构成的。每个滤波器在空间上（宽度和高度）都比较小，但是深度和输入数据一致。举例来说，卷积神经网络第一层的一个典型的滤波器的尺寸可以是5x5x3（宽高都是5像素，深度是3是因为图像应为颜色通道，所以有3的深度）。在前向传播的时候，让每个滤波器都在输入数据的宽度和高度上滑动（更精确地说是卷积），然后计算整个滤波器和输入数据任一处的内积。当滤波器沿着输入数据的宽度和高度滑过后，会生成一个2维的激活图（activation map），激活图给出了在每个空间位置处滤波器的反应。直观地来说，网络会让滤波器学习到当它看到某些类型的视觉特征时就激活，具体的视觉特征可能是某些方位上的边界，或者在第一层上某些颜色的斑点，甚至可以是网络更高层上的蜂巢状或者车轮状图案。

在每个卷积层上，我们会有一整个集合的滤波器（比如12个），每个都会生成一个不同的二维激活图。将这些激活映射在深度方向上层叠起来就生成了输出数据。

**以大脑做比喻**：如果你喜欢用大脑和生物神经元来做比喻，那么输出的3D数据中的每个数据项可以被看做是神经元的一个输出，而该神经元只观察输入数据中的一小部分，并且和空间上左右两边的所有神经元共享参数（因为这些数字都是使用同一个滤波器得到的结果）。现在开始讨论神经元的连接，它们在空间中的排列，以及它们参数共享的模式。  

**局部连接**：在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的。相反，我们让每个神经元只与输入数据的一个局部区域连接。该连接的空间大小叫做神经元的**感受野（receptive field）**，它的尺寸是一个超参数（其实就是滤波器的空间尺寸）。在深度方向上，这个连接的大小总是和输入量的深度相等。需要再次强调的是，我们对待空间维度（宽和高）与深度维度是不同的：连接在空间（宽高）上是局部的，但是在深度上总是和输入数据的深度一致。

_例1_：假设输入数据体尺寸为[32x32x3]（比如CIFAR-10的RGB图像），如果感受野（或滤波器尺寸）是5x5，那么卷积层中的每个神经元会有输入数据体中[5x5x3]区域的权重，共5x5x3=75个权重（还要加一个偏差参数）。注意这个连接在深度维度上的大小必须为3，和输入数据体的深度一致。

_例2_：假设输入数据体的尺寸是[16x16x20]，感受野尺寸是3x3，那么卷积层中每个神经元和输入数据体就有3x3x20=180个连接。再次提示：在空间上连接是局部的（3x3），但是在深度上是和输入数据体一致的（20）。

![][54]![][59]

**左边**：红色的是输入数据体（比如CIFAR-10中的图像），蓝色的部分是第一个卷积层中的神经元。卷积层中的每个神经元都只是与输入数据体的一个局部在空间上相连，但是与输入数据体的所有深度维度全部相连（所有颜色通道）。在深度方向上有多个神经元（本例中5个），它们都接受输入数据的同一块区域（**感受野**相同）。至于深度列的讨论在下文中有。

**右边**：神经网络章节中介绍的神经元保持不变，它们还是计算权重和输入的内积，然后进行激活函数运算，只是它们的连接被限制在一个局部空间。

![][54]

**空间排列**：上文讲解了卷积层中每个神经元与输入数据体之间的连接方式，但是尚未讨论输出数据体中神经元的数量，以及它们的排列方式。3个超参数控制着输出数据体的尺寸：**深度（depth），步长（stride）**和**零填充（zero-padding）**。下面是对它们的讨论：

1. 首先，输出数据体的深度是一个超参数：它和使用的滤波器的数量一致，而每个滤波器在输入数据中寻找一些不同的东西。举例来说，如果第一个卷积层的输入是原始图像，那么在深度维度上的不同神经元将可能被不同方向的边界，或者是颜色斑点激活。我们将这些沿着深度方向排列、感受野相同的神经元集合称为**深度列（depth column）**，也有人使用纤维（fibre）来称呼它们。
2. 其次，在滑动滤波器的时候，必须指定步长。当步长为1，滤波器每次移动1个像素。当步长为2（或者不常用的3，或者更多，这些在实际中很少使用），滤波器滑动时每次移动2个像素。这个操作会让输出数据体在空间上变小。
3. 在下文可以看到，有时候将输入数据体用0在边缘处进行填充是很方便的。这个**零填充（zero-padding）**的尺寸是一个超参数。零填充有一个良好性质，即可以控制输出数据体的空间尺寸（最常用的是用来保持输入数据体在空间上的尺寸，这样输入和输出的宽高都相等）。  

输出数据体在空间上的尺寸可以通过输入数据体尺寸（W），卷积层中神经元的感受野尺寸（F），步长（S）和零填充的数量（P）的函数来计算。（_**译者注**：这里假设输入数组的空间形状是正方形，即高度和宽度相等_）输出数据体的空间尺寸为(W-F +2P)/S+1。比如输入是7x7，滤波器是3x3，步长为1，填充为0，那么就能得到一个5x5的输出。如果步长为2，输出就是3x3。下面是例子：

![][54]![][60]

空间排列的图示。在本例中只有一个空间维度（x轴），神经元的感受野尺寸F=3，输入尺寸W=5，零填充P=1。左边：神经元使用的步长S=1，所以输出尺寸是(5-3+2)/1+1=5。右边：神经元的步长S=2，则输出尺寸是(5-3+2)/2+1=3。注意当步长S=3时是无法使用的，因为它无法整齐地穿过数据体。从等式上来说，因为(5-3+2)=4是不能被3整除的。

本例中，神经元的权重是[1,0,-1]，显示在图的右上角，偏差值为0。这些权重是被所有黄色的神经元共享的（参数共享的内容看下文相关内容）。

![][54]

_使用零填充_：在上面左边例子中，注意输入维度是5，输出维度也是5。之所以如此，是因为感受野是3并且使用了1的零填充。如果不使用零填充，则输出数据体的空间维度就只有3，因为这就是滤波器整齐滑过并覆盖原始数据需要的数目。一般说来，当步长!["S=1"][61]时，零填充的值是!["P=\(F-1\)/2"][62]，这样就能保证输入和输出数据体有相同的空间尺寸。这样做非常常见，在介绍卷积神经网络的结构的时候我们会详细讨论其原因。  

_步长的限制_：注意这些空间排列的超参数之间是相互限制的。举例说来，当输入尺寸!["W=10"][63]，不使用零填充则!["P=0"][64]，滤波器尺寸!["F=3"][65]，这样步长!["S=2"][66]就行不通，因为!["\(W-F+2P\)/S+1=\(10-3+0\)/2+1=4.5"][67]，结果不是整数，这就是说神经元不能整齐对称地滑过输入数据体。因此，这些超参数的设定就被认为是无效的，一个卷积神经网络库可能会报出一个错误，或者修改零填充值来让设置合理，或者修改输入数据体尺寸来让设置合理，或者其他什么措施。在后面的卷积神经网络结构小节中，读者可以看到合理地设置网络的尺寸让所有的维度都能正常工作，这件事可是相当让人头痛的。而使用零填充和遵守其他一些设计策略将会有效解决这个问题。  

_真实案例_：[Krizhevsky__][68]构架赢得了2012年的ImageNet挑战，其输入图像的尺寸是[227x227x3]。在第一个卷积层，神经元使用的感受野尺寸!["F=11"][69]，步长!["S=4"][70]，不使用零填充!["P=0"][64]。因为(227-11)/4+1=55，卷积层的深度!["K=96"][71]，则卷积层的输出数据体尺寸为[55x55x96]。55x55x96个神经元中，每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接。在深度列上的96个神经元都是与输入数据体中同一个[11x11x3]区域连接，但是权重不同。有一个有趣的细节，在原论文中，说的输入图像尺寸是224x224，这是肯定错误的，因为(224-11)/4+1的结果不是整数。这件事在卷积神经网络的历史上让很多人迷惑，而这个错误到底是怎么发生的没人知道。我的猜测是Alex忘记在论文中指出自己使用了尺寸为3的额外的零填充。  

**参数共享**：在卷积层中使用参数共享是用来控制参数的数量。就用上面的例子，在第一个卷积层就有55x55x96=290,400个神经元，每个有11x11x3=364个参数和1个偏差。将这些合起来就是290400x364=105,705,600个参数。单单第一层就有这么多参数，显然这个数目是非常大的。

作一个合理的假设：如果一个特征在计算某个空间位置(x,y)的时候有用，那么它在计算另一个不同位置(x2,y2)的时候也有用。基于这个假设，可以显著地减少参数数量。换言之，就是将深度维度上一个单独的2维切片看做**深度切片（depth slice）**，比如一个数据体尺寸为[55x55x96]的就有96个深度切片，每个尺寸为[55x55]。在每个深度切片上的神经元都使用同样的权重和偏差。在这样的参数共享下，例子中的第一个卷积层就只有96个不同的权重集了，一个权重集对应一个深度切片，共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）。在每个深度切片中的55x55个权重使用的都是同样的参数。在反向传播的时候，都要计算每个神经元对它的权重的梯度，但是需要把同一个深度切片上的所有神经元对权重的梯度累加，这样就得到了对共享权重的梯度。这样，每个切片只更新一个权重集。

注意，如果在一个深度切片中的所有权重都使用同一个权重向量，那么卷积层的前向传播在每个深度切片中可以看做是在计算神经元权重和输入数据体的**卷积**（这就是"卷积层"名字由来）。这也是为什么总是将这些权重集合称为**滤波器（filter）**（或**卷积核（kernel）**），因为它们和输入进行了卷积。

![][54]![][72]Krizhevsky等学习到的滤波器例子。这96个滤波器的尺寸都是[11x11x3]，在一个深度切片中，每个滤波器都被55x55个神经元共享。注意参数共享的假设是有道理的：如果在图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。所以在卷积层的输出数据体的55x55个不同位置中，就没有必要重新学习去探测一个水平边界了。![][54]

注意有时候参数共享假设可能没有意义，特别是当卷积神经网络的输入图像是一些明确的中心结构时候。这时候我们就应该期望在图片的不同位置学习到完全不同的特征。一个具体的例子就是输入图像是人脸，人脸一般都处于图片中心。你可能期望不同的特征，比如眼睛特征或者头发特征可能（也应该）会在图片的不同位置被学习。在这个例子中，通常就放松参数共享的限制，将层称为**局部连接层**（Locally-Connected Layer）。

**Numpy例子**：为了让讨论更加的具体，我们用代码来展示上述思路。假设输入数据体是numpy数组**X**。那么：

* 一个位于**(x,y)**的深度列（或纤维）将会是**X[x,y,:]**。  
* 在深度为**d**处的深度切片，或激活图应该是**X[:,:,d]**。  

_卷积层例子_：假设输入数据体**X**的尺寸**X.shape:(11,11,4)**，不使用零填充（!["P=0"][64]），滤波器的尺寸是!["F=5"][73]，步长!["S=2"][66]。那么输出数据体的空间尺寸就是(11-5)/2+1=4，即输出数据体的宽度和高度都是4。那么在输出数据体中的激活映射（称其为**V**）看起来就是下面这样（在这个例子中，只有部分元素被计算）：

* **V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0  
**
* **V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0  
**
* **V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0  
**
* **V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0**  

在numpy中，*****操作是进行数组间的逐元素相乘。权重向量**W0**是该神经元的权重，**b0**是其偏差。在这里，**W0**被假设尺寸是**W0.shape: (5,5,4)**，因为滤波器的宽高是5，输入数据量的深度是4。注意在每一个点，计算点积的方式和之前的常规神经网络是一样的。同时，计算内积的时候使用的是同一个权重和偏差（因为参数共享），在宽度方向的数字每次上升2（因为步长为2）。要构建输出数据体中的第二张激活图，代码应该是：

* **V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1  
**
* **V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1  
**
* **V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1  
**
* **V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1**  
* **V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 **（在y方向上）  
* **V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 **（或两个方向上同时）

我们访问的是**V**的深度维度上的第二层（即index1），因为是在计算第二个激活图，所以这次试用的参数集就是**W1**了。在上面的例子中，为了简洁略去了卷积层对于输出数组**V**中其他部分的操作。还有，要记得这些卷积操作通常后面接的是ReLU层，对激活图中的每个元素做激活函数运算，这里没有显示。

**小结**： 我们总结一下卷积层的性质：

对这些超参数，常见的设置是!["F=3"][65]，!["S=1"][61]，!["P=1"][74]。同时设置这些超参数也有一些约定俗成的惯例和经验，可以在下面的卷积神经网络结构章节中查看。

卷积层演示：下面是一个卷积层的运行演示。因为3D数据难以可视化，所以所有的数据（输入数据体是蓝色，权重数据体是红色，输出数据体是绿色）都采取将深度切片按照列的方式排列展现。输入数据体的尺寸是!["W_1=5,H_1=5,D_1=3"][75]，卷积层参数!["K=2,F=3,S=2,P=1"][76]。就是说，有2个滤波器，滤波器的尺寸是<img src="" http:="" zhihu.com="" equation?tex="3%5Ccdot+3&quot;&quot;" alt="" 3="" [1]:="" "http:="" link.zhihu.com="" ?target="http%3A//vision.stanford.edu/teaching/cs231n/index.html&quot;" [2]:="" [3]:="" [4]:="" [5]:="" [6]:="" [7]:="" "https:="" pic4.zhimg.com="" 77465c8318e6c4d40df274b92602d83f_b.png"="" [8]:="" [9]:="" zhuanlan.zhihu.com="" p="" 20878530?refer="intelligentunit&quot;" [10]:="" [11]:="" 20894041?refer="intelligentunit&quot;" [12]:="" 20900216?refer="intelligentunit&quot;" [13]:="" [14]:="" 20918580?refer="intelligentunit&quot;" [15]:="" 20945670?refer="intelligentunit&quot;" [16]:="" 21102293?refer="intelligentunit&quot;" [17]:="" [18]:="" 21360434?refer="intelligentunit&quot;" [19]:="" 21387326?refer="intelligentunit&quot;" [20]:="" [21]:="" 21407711?refer="intelligentunit&quot;" [22]:="" [23]:="" 21462488?refer="intelligentunit&quot;" [24]:="" 21513367?refer="intelligentunit&quot;" [25]:="" [26]:="" 21560667?refer="intelligentunit&quot;" [27]:="" [28]:="" 21741716?refer="intelligentunit&quot;" [29]:="" 21798784?refer="intelligentunit&quot;" [30]:="" [31]:="" 22038289?refer="intelligentunit&quot;" [32]:="" [33]:="" 21441838?refer="intelligentunit&quot;" [34]:="" [35]:="" 21941485?refer="intelligentunit&quot;" [36]:="" [37]:="" 21946525?refer="intelligentunit&quot;" [38]:="" www.zhihu.com="" people="" 313544833f1060900fcb4f6a75c9f6b6"="" [39]:="" 21354230?refer="intelligentunit&quot;" [40]:="" 928affb05b0b70a2c12e109d63b6bae5"="" [41]:="" question="" 41907061"="" [42]:="" 20870307?refer="intelligentunit&quot;" [43]:="" intelligentunit"="" [44]:="" 584f06e4ed2edc6007e4793179e7cdc1"="" [45]:="" hmonkey"="" [46]:="" e7fcc05b0cf8a90a3e676d0206f888c9"="" [47]:="" f11e78650e8185db2b013af42fd9a481"="" [48]:="" 77465c8318e6c4d40df274b92602d83f_200x112.png"="" [49]:="" vision.stanford.edu="" teaching="" cs231n="" index.html"="" [50]:="" [51]:="" du-ke"="" [52]:="" kun-kun-97-81"="" [53]:="" li-yi-ying-73"="" [54]:="" pic1.zhimg.com="" 307530cfd15f5ca2461a2b6f633f93b8_b.png"="" [55]:="" pic2.zhimg.com="" 2ef08bb4cf60805d726b2d6db39dd985_b.jpg"="" [56]:="" [57]:="" pic3.zhimg.com="" d9259be829b1cdb3d98a399ebc56defa_b.jpg"="" [58]:="" [59]:="" ba9dcfa847a71cb695c2653230ea9147_b.jpg"="" [60]:="" 90af0bd67ba498239688c81fd61bbc66_b.jpg"="" [61]:="" [62]:="" [63]:="" [64]:="" [65]:="" [66]:="" [67]:="" [68]:="" [69]:="" [70]:="" [71]:="" [72]:="" dd62e1d75bda9b592dabb91627d68aa6_b.jpg"="" [73]:="" [74]:="" [75]:="" [76]:="" <="" div="">
